{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install yfinance\n",
    "!pip install pandas_datareader\n",
    "!pip install matplotlib\n",
    "!pip install pandas-datareader\n",
    "!pip install tensorflow\n",
    "!pip install Keras\n",
    "!pip install scikit-learn\n",
    "!pip install yfinance pyfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install numpy==1.16.1 pandas==0.23.3 matplotlib==2.2.3 pandas-datareader==0.7.0 tensorflow==1.13.1 Keras==2.2.4 scikit-learn==0.20.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas_datareader import data as pdr\n",
    "import tensorflow\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.layers import Dense,Dropout,BatchNormalization,Conv1D,Flatten,MaxPooling1D,LSTM\n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint,TensorBoard,ReduceLROnPlateau\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.models import load_model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import pyfolio as pf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date=datetime.datetime(2000, 8, 30)\n",
    "end_date=datetime.datetime(2022, 8,31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yfSymbol = \"GC=F\"\n",
    "#Import stock data\n",
    "!pip install yfinance\n",
    "\n",
    "import yfinance as yf\n",
    "\n",
    "from pandas_datareader import data as pdr\n",
    "import yfinance as yf\n",
    "yf.pdr_override()\n",
    "df = pdr.get_data_yahoo(yfSymbol, start=start_date, end=end_date)\n",
    "df.drop(\"Adj Close\",axis=1,inplace=True)\n",
    "print(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,10))\n",
    "plt.plot(df['Close'], label=\"Close\")\n",
    "#plt.plot(y_pred_train_mix, label=\"prediction by mix model\")\n",
    "plt.legend(fontsize=20)\n",
    "plt.grid(axis=\"both\")\n",
    "plt.title(\"Dzienna cena zamknięcia indeksu złota GC=F \" + yfSymbol + \", \" + \"z okresu od 2000-08-30 do 2022-08-30\",fontsize=18)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_year=start_date.year\n",
    "start_month=start_date.month\n",
    "end_year=end_date.year\n",
    "end_month=end_date.month\n",
    "\n",
    "first_days=[]\n",
    "# First year\n",
    "for month in range(start_month,13):\n",
    "    first_days.append(min(df[str(start_year)+\"-\"+str(month)].index))\n",
    "# Other years\n",
    "for year in range(start_year+1,end_year):\n",
    "    for month in range(1,13):\n",
    "        first_days.append(min(df[str(year)+\"-\"+str(month)].index))\n",
    "# Last year\n",
    "for month in range(1,end_month+1):\n",
    "    first_days.append(min(df[str(end_year)+\"-\"+str(month)].index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monthly_df(df):\n",
    "\n",
    "    dfm=df.resample(\"M\").mean()\n",
    "    dfm=dfm[:-1] # As we said, we do not consider the month of end_date\n",
    "    \n",
    "    dfm[\"fd_cm\"]=first_days[:-1]\n",
    "    dfm[\"fd_nm\"]=first_days[1:]\n",
    "    dfm[\"fd_cm_open\"]=np.array(df.loc[first_days[:-1],\"Open\"])\n",
    "    dfm[\"fd_nm_open\"]=np.array(df.loc[first_days[1:],\"Open\"])\n",
    "    #dfm[\"fd_cm_open1\"]=np.array(df.loc[first_days[:-1],\"Close\"])\n",
    "    #dfm[\"fd_nm_open1\"]=np.array(df.loc[first_days[1:],\"Close\"])\n",
    "    dfm[\"quot\"]=dfm[\"fd_nm_open\"].divide(dfm[\"fd_cm_open\"])\n",
    "    #dfm[\"quot1\"]=dfm[\"fd_nm_open1\"].divide(dfm[\"fd_cm_open1\"])\n",
    "    \n",
    "    dfm[\"mv_avg_12\"]= dfm[\"Open\"].rolling(window=12).mean().shift(1)\n",
    "    dfm[\"mv_avg_24\"]= dfm[\"Open\"].rolling(window=24).mean().shift(1)\n",
    "    \n",
    "    dfm=dfm.iloc[24:,:] # we remove the first 24 months, since they do not have the 2-year moving average\n",
    "    \n",
    "    return dfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfm=monthly_df(df)\n",
    "\n",
    "print(dfm.head())\n",
    "print(dfm.tail())\n",
    "\n",
    "#each month of dfm contains the moving averages of the previous 12 and 24 months (excluding the current month)\n",
    "print(dfm.loc[\"2015-03\",\"mv_avg_12\"])\n",
    "print(dfm.loc[\"2010-03\":\"2011-02\",\"Open\"])\n",
    "print(dfm.loc[\"2010-03\":\"2011-02\",\"Open\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yield_gross(df,v):\n",
    "    prod=(v*df[\"quot\"]+1-v).prod()\n",
    "    n_years=len(v)/12\n",
    "    return (prod-1)*100,((prod**(1/n_years))-1)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def cumulative_returns(df,v):\n",
    "  #(returns + 1.0).cumprod()\n",
    "    #prod=(v*df[\"quot\"]+1-v).prod()\n",
    "    #n_years=len(v)/12\n",
    "    #return (prod-1)*100,((prod**(1/n_years))-1)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tax_cg=0.23\n",
    "tax_cg=0\n",
    "#comm_bk=0.001\n",
    "comm_bk=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_ones(u):\n",
    "    \n",
    "    u_ = np.r_[0,u,0]\n",
    "    i = np.flatnonzero(u_[:-1] != u_[1:])\n",
    "    v,w = i[::2],i[1::2]\n",
    "    if len(v)==0:\n",
    "        return np.zeros(len(u)),0\n",
    "    \n",
    "    n,m = len(v),len(u)\n",
    "    o = np.zeros(n*m,dtype=int)\n",
    "\n",
    "    r = np.arange(n)*m\n",
    "    o[v+r] = 1\n",
    "\n",
    "    if w[-1] == m:\n",
    "        o[w[:-1]+r[:-1]] = -1\n",
    "    else:\n",
    "        o[w+r] -= 1\n",
    "\n",
    "    out = o.cumsum().reshape(n,-1)\n",
    "    return out,n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u=np.array([0,1,1,0,1,1,1,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "separate_ones(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u=np.array([1,1,1,1,1,1,1,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "separate_ones(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u=np.array([1,1,0,0,1,1,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "separate_ones(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yield_net(df,v):\n",
    "    n_years=len(v)/12\n",
    "    \n",
    "    w,n=separate_ones(v)\n",
    "    A=(w*np.array(df[\"quot\"])+(1-w)).prod(axis=1)  # A is the product of each group of ones of 1 for df[\"quot\"]\n",
    "    A1p=np.maximum(0,np.sign(A-1)) # vector of ones where the corresponding element if  A  is > 1, other are 0\n",
    "    Ap=A*A1p # vector of elements of A > 1, other are 0\n",
    "    Am=A-Ap # vector of elements of A <= 1, other are 0\n",
    "    An=Am+(Ap-A1p)*(1-tax_cg)+A1p\n",
    "    prod=An.prod()*((1-comm_bk)**(2*n)) \n",
    "    \n",
    "    return (prod-1)*100,((prod**(1/n_years))-1)*100   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_window(data, window_size = 1):    \n",
    "    data_s = data.copy()\n",
    "    for i in range(window_size):\n",
    "        data = pd.concat([data, data_s.shift(-(i + 1))], axis = 1)\n",
    "        \n",
    "    data.dropna(axis=0, inplace=True)\n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dates = dfm.index\n",
    "print(df_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_model(dfm):\n",
    "    scaler=MinMaxScaler(feature_range=(0,1))\n",
    "    dg=pd.DataFrame(scaler.fit_transform(dfm[[\"High\",\"Low\",\"Open\",\"Close\",\"Volume\",\"fd_cm_open\",\\\n",
    "                                          \"mv_avg_12\",\"mv_avg_24\",\"fd_nm_open\"]].values))\n",
    "    print(dg)\n",
    "    X=dg[[0,1,2,3,4,5,6,7]]\n",
    "    print(X)\n",
    "    X=create_window(X,window)\n",
    "    X=np.reshape(X.values,(X.shape[0],window+1,8))\n",
    "    \n",
    "    y=np.array(dg[8][window:])\n",
    "    \n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window=5\n",
    "\n",
    "X,y=data_to_model(dfm)\n",
    "print(X.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtest=72\n",
    "\n",
    "X_train=X[:-mtest-1,:,:]\n",
    "X_test=X[-mtest-1:,:,:]\n",
    "y_train=y[:-mtest-1]\n",
    "y_test=y[-mtest-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_lstm1(window,features):\n",
    "    \n",
    "    model=Sequential()\n",
    "    model.add(LSTM(400, input_shape = (window,features), return_sequences=True))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(LSTM(250,  return_sequences=False)) # there is no need to specify input_shape here\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(125,kernel_initializer='uniform',activation='relu'))        \n",
    "    model.add(Dense(1,kernel_initializer='uniform',activation='relu'))\n",
    "    model.compile(loss='mse',optimizer=Adam(lr=0.001))\n",
    "    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lstm1=model_lstm1(window+1,8)\n",
    "print(model_lstm1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_lstm2(window,features):\n",
    "    \n",
    "    model=Sequential()\n",
    "    model.add(LSTM(200, input_shape = (window,features), return_sequences=True))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(LSTM(100,  return_sequences=False)) # there is no need to specify input_shape here\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(50,kernel_initializer='uniform',activation='relu'))        \n",
    "    model.add(Dense(1,kernel_initializer='uniform',activation='relu'))\n",
    "    model.compile(loss='mse',optimizer=Adam(lr=0.001))\n",
    "    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lstm2=model_lstm2(window+1,8)\n",
    "print(model_lstm2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_lstm3(window,features):\n",
    "    \n",
    "    model=Sequential()\n",
    "    model.add(LSTM(200, input_shape = (window,features), return_sequences=False))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(50,kernel_initializer='uniform',activation='relu'))        \n",
    "    model.add(Dense(1,kernel_initializer='uniform',activation='relu'))\n",
    "    model.compile(loss='mse',optimizer=Adam(lr=0.001))\n",
    "    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lstm3=model_lstm3(window+1,8)\n",
    "print(model_lstm3.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_lstm4(window,features):\n",
    "    \n",
    "    model=Sequential()\n",
    "    model.add(LSTM(200, input_shape = (window,features), return_sequences=False))     \n",
    "    model.add(Dense(1,kernel_initializer='uniform',activation='relu'))\n",
    "    model.compile(loss='mse',optimizer=Adam(lr=0.001))\n",
    "    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lstm4=model_lstm4(window+1,8)\n",
    "print(model_lstm4.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def model_mix(window,features):\n",
    "    \n",
    "#    model=Sequential()\n",
    "#    model.add(Conv1D(input_shape=(window,features),filters=32,kernel_size=2,strides=1,activation='relu',padding='same'))\n",
    "#    model.add(Conv1D(filters=64,kernel_size=2,strides=1,activation='relu',padding='same'))\n",
    "#    model.add(LSTM(300, return_sequences=True))\n",
    "#    model.add(Dropout(0.5))\n",
    "#    model.add(LSTM(200,  return_sequences=False))\n",
    "#    model.add(Dropout(0.5))\n",
    "#    model.add(Dense(100,kernel_initializer='uniform',activation='relu'))        \n",
    "#    model.add(Dense(1,kernel_initializer='uniform',activation='relu'))\n",
    "#    model.compile(loss='mse',optimizer=Adam(lr=0.001))\n",
    "    \n",
    "    \n",
    "#    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_lstm5(window,features):\n",
    "    \n",
    "    model=Sequential()\n",
    "    model.add(LSTM(100, input_shape = (window,features), return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(100,  return_sequences=True)) # there is no need to specify input_shape here\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(100,  return_sequences=True)) # there is no need to specify input_shape here\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(100,  return_sequences=False)) # there is no need to specify input_shape here\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(20,kernel_initializer='uniform',activation='relu'))        \n",
    "    model.add(Dense(1,kernel_initializer='uniform',activation='relu'))\n",
    "    model.compile(loss='mse',optimizer=Adam(lr=0.001))\n",
    "    \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lstm5=model_lstm5(window+1,8)\n",
    "print(model_lstm5.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', patience=25, verbose=1,\\\n",
    "                                                 factor=0.25, min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_lstm1=model_lstm1.fit(X_train,y_train,epochs=400, batch_size=24, validation_data=(X_test, y_test), \\\n",
    "                  verbose=1, callbacks=[learning_rate_reduction],shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_lstm2=model_lstm2.fit(X_train,y_train,epochs=400, batch_size=24, validation_data=(X_test, y_test), \\\n",
    "                  verbose=1, callbacks=[learning_rate_reduction],shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_lstm3=model_lstm3.fit(X_train,y_train,epochs=400, batch_size=24, validation_data=(X_test, y_test), \\\n",
    "                  verbose=1, callbacks=[learning_rate_reduction],shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_lstm4=model_lstm4.fit(X_train,y_train,epochs=400, batch_size=24, validation_data=(X_test, y_test), \\\n",
    "                  verbose=1, callbacks=[learning_rate_reduction],shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_lstm5=model_lstm5.fit(X_train,y_train,epochs=400, batch_size=24, validation_data=(X_test, y_test), \\\n",
    "                  verbose=1, callbacks=[learning_rate_reduction],shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_lstm1.history['loss'])\n",
    "plt.plot(history_lstm1.history['val_loss'])\n",
    "plt.title('model_1')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_lstm2.history['loss'])\n",
    "plt.plot(history_lstm2.history['val_loss'])\n",
    "plt.title('model_2')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_lstm3.history['loss'])\n",
    "plt.plot(history_lstm3.history['val_loss'])\n",
    "plt.title('model_3')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_lstm4.history['loss'])\n",
    "plt.plot(history_lstm4.history['val_loss'])\n",
    "plt.title('model_4')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_lstm5.history['loss'])\n",
    "plt.plot(history_lstm5.history['val_loss'])\n",
    "plt.title('model_5')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_lstm.save_weights(\"lstm_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_mix=model_mix(window+1,8)\n",
    "#print(model_mix.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#history_mix=model_mix.fit(X_train,y_train,epochs=400, batch_size=24, validation_data=(X_test, y_test), \\\n",
    "                 # verbose=1, callbacks=[learning_rate_reduction],shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(history_mix.history['loss'])\n",
    "#plt.plot(history_mix.history['val_loss'])\n",
    "#plt.title('model loss')\n",
    "#plt.ylabel('loss')\n",
    "#plt.xlabel('epoch')\n",
    "#plt.legend(['train', 'test'], loc='upper right')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_mix.save_weights(\"mix_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred_train_lstm1=model_lstm1.predict(X_train)\n",
    "y_pred_train_lstm2=model_lstm2.predict(X_train)\n",
    "y_pred_train_lstm3=model_lstm3.predict(X_train)\n",
    "y_pred_train_lstm4=model_lstm4.predict(X_train)\n",
    "y_pred_train_lstm5=model_lstm5.predict(X_train)\n",
    "#y_pred_train_mix=model_mix.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "MAE = mean_absolute_error(y_train, y_pred_train_lstm1)\n",
    "print(\"mean_absolute_error\")\n",
    "print(MAE)\n",
    "\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "MAPE = mean_absolute_percentage_error(y_train, y_pred_train_lstm1)\n",
    "print(\"mean_absolute_percentage_error\")\n",
    "print(MAPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "MAE = mean_absolute_error(y_train, y_pred_train_lstm2)\n",
    "print(\"mean_absolute_error\")\n",
    "print(MAE)\n",
    "\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "MAPE = mean_absolute_percentage_error(y_train, y_pred_train_lstm2)\n",
    "print(\"mean_absolute_percentage_error\")\n",
    "print(MAPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "MAE = mean_absolute_error(y_train, y_pred_train_lstm3)\n",
    "print(\"mean_absolute_error\")\n",
    "print(MAE)\n",
    "\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "MAPE = mean_absolute_percentage_error(y_train, y_pred_train_lstm3)\n",
    "print(\"mean_absolute_percentage_error\")\n",
    "print(MAPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "MAE = mean_absolute_error(y_train, y_pred_train_lstm4)\n",
    "print(\"mean_absolute_error\")\n",
    "print(MAE)\n",
    "\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "MAPE = mean_absolute_percentage_error(y_train, y_pred_train_lstm4)\n",
    "print(\"mean_absolute_percentage_error\")\n",
    "print(MAPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "MAE = mean_absolute_error(y_train, y_pred_train_lstm5)\n",
    "print(\"mean_absolute_error\")\n",
    "print(MAE)\n",
    "\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "MAPE = mean_absolute_percentage_error(y_train, y_pred_train_lstm5)\n",
    "print(\"mean_absolute_percentage_error\")\n",
    "print(MAPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,10))\n",
    "plt.plot(y_train, label=\"Cena otwarcia\")\n",
    "plt.plot(y_pred_train_lstm1, label=\"Cena obiczona przez model_1\")\n",
    "plt.plot(y_pred_train_lstm2, label=\"Cena obiczona przez model_2\")\n",
    "plt.plot(y_pred_train_lstm3, label=\"Cena obiczona przez model_3\")\n",
    "plt.plot(y_pred_train_lstm4, label=\"Cena obiczona przez model_4\")\n",
    "plt.plot(y_pred_train_lstm5, label=\"Cena obiczona przez model_5\")\n",
    "#plt.plot(y_pred_train_mix, label=\"prediction by mix model\")\n",
    "plt.legend(fontsize=20)\n",
    "plt.grid(axis=\"both\")\n",
    "plt.title(\"Wynik modeli na zbiorze walidacyjnym\",fontsize=25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All_y_pred_train_lstm = [y_pred_train_lstm,y_pred_train_lstm1,y_pred_train_lstm2,y_pred_train_lstm3]\n",
    "#print(All_y_pred_train_lstm)\n",
    "\n",
    "print(y_pred_train_lstm1.size)\n",
    "print(y_pred_train_lstm2.size)\n",
    "print(y_pred_train_lstm3.size)\n",
    "print(y_pred_train_lstm4.size)\n",
    "print(y_pred_train_lstm5.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred_lstm1=model_lstm1.predict(X_test)\n",
    "y_pred_lstm2=model_lstm2.predict(X_test)\n",
    "y_pred_lstm3=model_lstm3.predict(X_test)\n",
    "y_pred_lstm4=model_lstm4.predict(X_test)\n",
    "y_pred_lstm5=model_lstm5.predict(X_test)\n",
    "#y_pred_mix=model_mix.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "w_lstm1=np.diff(y_pred_lstm1.reshape(y_pred_lstm1.shape[0]),1)\n",
    "v_lstm1=np.maximum(np.sign(w_lstm1),0)\n",
    "print(v_lstm1)\n",
    "\n",
    "w_lstm2=np.diff(y_pred_lstm2.reshape(y_pred_lstm2.shape[0]),1)\n",
    "v_lstm2=np.maximum(np.sign(w_lstm2),0)\n",
    "print(v_lstm2)\n",
    "\n",
    "w_lstm3=np.diff(y_pred_lstm3.reshape(y_pred_lstm3.shape[0]),1)\n",
    "v_lstm3=np.maximum(np.sign(w_lstm3),0)\n",
    "print(v_lstm3)\n",
    "\n",
    "w_lstm4=np.diff(y_pred_lstm4.reshape(y_pred_lstm4.shape[0]),1)\n",
    "#print(w_lstm)\n",
    "v_lstm4=np.maximum(np.sign(w_lstm4),0)\n",
    "print(v_lstm4)\n",
    "\n",
    "w_lstm5=np.diff(y_pred_lstm5.reshape(y_pred_lstm5.shape[0]),1)\n",
    "#print(w_lstm)\n",
    "v_lstm5=np.maximum(np.sign(w_lstm5),0)\n",
    "print(v_lstm5)\n",
    "\n",
    "#w_mix=np.diff(y_pred_mix.reshape(y_pred_mix.shape[0]),1)\n",
    "#v_mix=np.maximum(np.sign(w_mix),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(60,20))\n",
    "plt.plot(y_test, label=\"Cena otwarcia\")\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(y_pred_lstm1, label=\"Cena obiczona przez model_1\")\n",
    "plt.plot(v_lstm1,label=\"Otwarcie i zamknięcie pozycji model_1\")\n",
    "\n",
    "plt.plot(y_pred_lstm2, label=\"Cena obiczona przez model_2\")\n",
    "plt.plot(v_lstm2,label=\"Otwarcie i zamknięcie pozycji model_2\")\n",
    "\n",
    "plt.plot(y_pred_lstm3, label=\"Cena obiczona przez model_3\")\n",
    "plt.plot(v_lstm3,label=\"Otwarcie i zamknięcie pozycji model_3\")\n",
    "\n",
    "plt.plot(y_pred_lstm4, label=\"Cena obiczona przez model_4\")\n",
    "plt.plot(v_lstm4,label=\"Otwarcie i zamknięcie pozycji model_4\")\n",
    "\n",
    "plt.plot(y_pred_lstm5, label=\"Cena obiczona przez model_5\")\n",
    "plt.plot(v_lstm5,label=\"Otwarcie i zamknięcie pozycji model_5\")\n",
    "\n",
    "#plt.plot(y_pred_mix, label=\"prediction mix\")\n",
    "#plt.plot(v_mix,label=\"In and out mix\")\n",
    "plt.legend(fontsize=20)\n",
    "plt.grid(axis=\"both\")\n",
    "plt.title(\"Cena otwarcia oraz otwarcie i zamknięcie pozycji przez modele\",fontsize=25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=dfm.iloc[-mtest:,:] \n",
    "v_bh=np.ones(test.shape[0])\n",
    "v_ma=test[\"fd_cm_open\"]>test[\"mv_avg_12\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gross_portfolio(df,w):\n",
    "    portfolio=[ (w*df[\"quot\"]+(1-w))[:i].prod() for i in range(len(w))]\n",
    "    return portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,10))\n",
    "plt.plot(gross_portfolio(test,v_bh),label=\"Portfolio 'Buy and Hold'\")\n",
    "plt.plot(gross_portfolio(test,v_ma),label=\"Portfolio Średniej ruchomej\")\n",
    "\n",
    "plt.plot(gross_portfolio(test,v_lstm1),label=\"Portfolio model_1\")\n",
    "plt.plot(gross_portfolio(test,v_lstm2),label=\"Portfolio model_2\")\n",
    "plt.plot(gross_portfolio(test,v_lstm3),label=\"Portfolio model_3\")\n",
    "plt.plot(gross_portfolio(test,v_lstm4),label=\"Portfolio model_4\")\n",
    "plt.plot(gross_portfolio(test,v_lstm5),label=\"Portfolio model_5\")\n",
    "#plt.plot(gross_portfolio(test,v_mix),label=\"Portfolio Mix\")\n",
    "plt.legend(fontsize=20)\n",
    "plt.grid(axis=\"both\")\n",
    "plt.title(\"Gross portfolios of three methods\", fontsize=25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Wyniki {:.2f} letniego testu z okresu od {} do {} \\n\".format(len(v_bh)/12,str(test.loc[test.index[0],\"fd_cm\"])[:10],\\\n",
    "str(test.loc[test.index[-1],\"fd_nm\"])[:10]))\n",
    "\n",
    "results=pd.DataFrame({})\n",
    "#results[\"Method\"]=[\"Buy and hold\",\"Moving average\",\"LSTM\",\"Mix\"]\n",
    "#results[\"Method\"]=[\"Buy and hold\",\"Moving average\",\"LSTM\"]\n",
    "results[\"Metoda\"]=[\"'Buy and hold'\",\"Średnia ruchoma\",\"model_1\",\"model_2\",\"model_3\",\"model_4\",\"model_5\"]\n",
    "\n",
    "#vs=[v_bh,v_ma,v_lstm,v_mix]\n",
    "vs=[v_bh,v_ma,v_lstm1,v_lstm2,v_lstm3,v_lstm4,v_lstm5]\n",
    "results[\"Całkowity zysk brutto\"]=[str(round(yield_gross(test,vi)[0],2))+\" %\" for vi in vs]\n",
    "results[\"Roczny zysk brutto\"]=[str(round(yield_gross(test,vi)[1],2))+\" %\" for vi in vs]\n",
    "#results[\"Total net yield\"]=[str(round(yield_net(test,vi)[0],2))+\" %\" for vi in vs]\n",
    "#results[\"Annual net yield\"]=[str(round(yield_net(test,vi)[1],2))+\" %\" for vi in vs]\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startSimulation = print(str(test.loc[test.index[0],\"fd_cm\"])[:10])\n",
    "endSimulation = print(str(test.loc[test.index[-1],\"fd_nm\"])[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datesSimulation = test.index\n",
    "print(type(datesSimulation))\n",
    "#print(df_dates.loc[\"2010-03\":\"2011-02\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns\n",
    "print(test['quot'])\n",
    "print(len(test['quot']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = test['quot'].shift(-1) * v_lstm\n",
    "\n",
    "# Drop the missing values\n",
    "data1.dropna(inplace=True)\n",
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#signal\n",
    "print(v_lstm)\n",
    "print(len(v_lstm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(datesSimulation))\n",
    "print(len(y_pred_train_lstm))\n",
    "#print(y_pred_train_lstm)\n",
    "#df1 = pd.DataFrame(y_pred_train_lstm)\n",
    "#print(type(df1))\n",
    "#df1 = df1.squeeze()\n",
    "#datesSimulation['outOfSimulation'] = y_pred_train_lstm\n",
    "#df1 = y_pred_train_lstm.pct_change()\n",
    "#df['target'] = np.where(df['returns'].shift(-1) > 0, 1, 0)\n",
    "#print(datesSimulation.head())\n",
    "#print(datesSimulation.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_returns = df1.pct_change()\n",
    "df1_returns.dropna(inplace=True)\n",
    "print(df1_returns)\n",
    "print(type(df1_returns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cumulative_returns(returns):\n",
    "\n",
    "    res = (returns + 1.0).cumprod()\n",
    "    res.columns = ['cumulative return']\n",
    "\n",
    "    return res\n",
    "cret = cumulative_returns(df1_returns)\n",
    "print(cret)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,10))\n",
    "plt.plot(cret, label=\"cumulative_returns\")\n",
    "#plt.plot(y_pred_train_mix, label=\"prediction by mix model\")\n",
    "plt.legend(fontsize=20)\n",
    "plt.grid(axis=\"both\")\n",
    "plt.title(\"cumulative_returns v_lstm\",fontsize=18)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5238573367df39f7286bb46f9ff5f08f63a01a80960060ce41e3c79b190280fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
